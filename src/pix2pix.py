import pytorch_lightning as pl
import torch
import torch.nn.functional as F
import torch.optim as o
import torch.nn as nn

from torchmetrics.image import SpectralAngleMapper
from torchmetrics.functional import peak_signal_noise_ratio, accuracy, structural_similarity_index_measure
from torchmetrics.functional.image import relative_average_spectral_error, spectral_angle_mapper

import config as c
import src.utils as u
from src.models.unet_model import Generator as Unet
from src.models.unet2d_model import Generator as Unet2D
from src.models.fp_unet_model import Generator as FP_Unet
from src.models.discriminator_model import Discriminator

class Pix2Pix(pl.LightningModule):
    def __init__(self, run):
        super(Pix2Pix, self).__init__()
        # self.save_hyperparameters()
        # Important to disable automatic optimization as it 
        # will be done manually as there are two optimizators
        self.automatic_optimization = False
        self.generator_lr = c.LEARNING_RATE               # Generator learning rate
        self.discriminator_lr = c.LEARNING_RATE       # Discriminator learning rate

        # Models
        self.discriminator = Discriminator(in_channels_x=c.SHAPE_X[0], in_channels_y=c.SHAPE_Y[0]).to(c.DEVICE)
        match c.GENERATOR_MODEL:
            case "unet":
                self.generator = Unet(in_channels=c.SHAPE_X[0], out_channels=c.SHAPE_Y[0], features=64).to(c.DEVICE)
            case "unet2d":
                self.generator = Unet2D(in_channels=c.SHAPE_X[0], out_channels=c.SHAPE_Y[0], features=64).to(c.DEVICE)
            case "fp_unet":
                self.generator = FP_Unet(in_channels=c.SHAPE_X[0], out_channels=c.SHAPE_Y[0], features=64).to(c.DEVICE)
            case _:
                print("No valid generator model defined.")

        # Loss Functions
        self.BCE = nn.BCEWithLogitsLoss()
        self.L1_LOSS = nn.L1Loss()
        self.SPECTRAL_LOSS = SpectralAngleMapper().to(c.DEVICE)

        # Neptune run
        self.run = run

    def forward(self, x):
        return self.generator(x)
    
    def generator_loss(self, prediction_image, target_image, prediction_label, target_label, real_label):
        """
        Generator loss (a combination of): 
            1 - Binary Cross-Entropy
                Between predicted labels (generated by the discriminator) and target labels which is all 1s
            2 - L1 / Mean Absolute Error (weighted by lambda)
                Between generated image and target image
            3 - Spectral Loss (Spectral Angle)
                Between generated image and target image
            4 - LFM Loss (Feature Matching Loss)
                Between weights from all layers of the discriminator
        """
        # Adverserial loss
        BCE_loss = self.BCE(prediction_label[0], torch.ones_like(target_label)) * c.ADV_LAMDA
        # LFM loss
        LFM_loss = torch.zeros((1,1,1,1)).to(c.DEVICE)
        LFM_weights = [1./16, 1./8, 1./4, 1./4, 1./2, 1.]
        for i, tensors in enumerate(zip(prediction_label[1], real_label[1])):
            LFM_loss += self.L1_LOSS(tensors[0], tensors[1]) * LFM_weights[i] * c.LFM_LAMBDA
        # Other losses
        L1 = self.L1_LOSS(prediction_image, target_image) * c.L1_LAMBDA
        SPEC = self.SPECTRAL_LOSS(prediction_image, target_image) * c.SPEC_LAMBDA

        return BCE_loss, L1, SPEC, LFM_loss
    
    def discriminator_loss(self, prediction_label, target_label):
        """
        Discriminator loss: 
            1 - Binary Cross-Entropy
                Between predicted labels (generated by the discriminator) and target labels
                The target would be all 0s if the input of the discriminator is the generated image (generator)
                The target would be all 1s if the input of the discriminator is the target image (dataloader)
        """
        bce_loss = self.BCE(prediction_label, target_label) # index 0 since these are the output weights
        return bce_loss
    
    def configure_optimizers(self):
        """
        Using Adam optimizer for both generator and discriminator
        Both would have different initial learning rates
        Stochastic Gradient Descent with Warm Restarts is also added as learning scheduler (https://arxiv.org/abs/1608.03983)
        """
        # Optimizers
        generator_optimizer = o.Adam(self.generator.parameters(), lr=self.generator_lr, weight_decay=1e-5)
        discriminator_optimizer = o.Adam(self.discriminator.parameters(), lr=self.discriminator_lr, weight_decay=1e-5)
        # Learning Scheduler Generator
        gen_const_lr = o.lr_scheduler.ConstantLR(generator_optimizer, factor=1.0)
        gen_exp_lr = o.lr_scheduler.ExponentialLR(generator_optimizer, gamma=c.LR_GAMMA)
        generator_lr_scheduler = o.lr_scheduler.SequentialLR(generator_optimizer, [gen_const_lr, gen_exp_lr], [c.LR_START_DECAY])
        # Learning Scheduler Discriminator
        dis_const_lr = o.lr_scheduler.ConstantLR(discriminator_optimizer, factor=1.0)
        dis_exp_lr = o.lr_scheduler.ExponentialLR(discriminator_optimizer, gamma=c.LR_GAMMA)
        discriminator_lr_scheduler = o.lr_scheduler.SequentialLR(discriminator_optimizer, [dis_const_lr, dis_exp_lr], [c.LR_START_DECAY])

        return [generator_optimizer, discriminator_optimizer], [generator_lr_scheduler, discriminator_lr_scheduler]

    def training_step(self, batch, batch_idx):
        # Optimizers
        generator_optimizer, discriminator_optimizer = self.optimizers()
        generator_lr_scheduler, discriminator_lr_scheduler = self.lr_schedulers()
        
        image, target = batch
        image_i, image_j = (image, image) #torch.split(image, c.BATCH_SIZE)
        target_i, target_j = (target, target) #torch.split(target, c.BATCH_SIZE)
        # Should Disc and Gen be trained on different images?
        
        ######################################
        #  Discriminator Loss and Optimizer  #
        ######################################
        # Generator Feed-Forward
        generator_prediction = self.forward(image_i)
        #generator_prediction = torch.clip(generator_prediction, 0, 1)
        # Discriminator Feed-Forward
        discriminator_prediction_real = self.discriminator(image_i, target_i)
        discriminator_prediction_fake = self.discriminator(image_i, generator_prediction)
        # Discriminator Loss
        discriminator_label_real = self.discriminator_loss(discriminator_prediction_real[0], 
                                                           torch.ones_like(discriminator_prediction_real[0]))
        discriminator_label_fake = self.discriminator_loss(discriminator_prediction_fake[0],
                                                           torch.zeros_like(discriminator_prediction_fake[0]))
        discriminator_loss = discriminator_label_real + discriminator_label_fake
        # Discriminator Optimizer
        discriminator_optimizer.zero_grad()
        discriminator_loss.backward()
        discriminator_optimizer.step()
        discriminator_lr_scheduler.step()
        
        ##################################
        #  Generator Loss and Optimizer  #
        ##################################
        #  Generator Feed-Forward
        generator_prediction = self.forward(image_j)
        #generator_prediction = torch.clip(generator_prediction, 0, 1)
        # Discriminator Feed-Forward
        discriminator_prediction_fake = self.discriminator(image_j, generator_prediction)
        discriminator_prediction_real = self.discriminator(image_i, target_i)
        # Generator loss
        generator_loss_tuple = self.generator_loss(generator_prediction, target_j, discriminator_prediction_fake, 
                                             torch.ones_like(discriminator_prediction_fake[0]), 
                                             discriminator_prediction_real)
        generator_bce_loss, generator_l1_loss, generator_spec_loss, generator_lfm_loss = generator_loss_tuple
        generator_loss = (generator_bce_loss * c.ADV_LAMDA) + (generator_l1_loss * c.L1_LAMBDA) + (generator_spec_loss * c.SPEC_LAMBDA) + (generator_lfm_loss * c.LFM_LAMBDA)
        # Generator Optimizer
        generator_optimizer.zero_grad()
        generator_loss.backward()
        generator_optimizer.step()
        generator_lr_scheduler.step()
        
        # Progressbar and Logging
        current_loss = {}
        current_loss["train/gen/loss"] = generator_loss.item()
        current_loss["train/dis/loss"] = discriminator_loss.item()
        current_loss['train/gen/l1_loss'] = generator_l1_loss.item()
        current_loss['train/gen/gan_loss'] = generator_bce_loss.item()
        current_loss['train/gen/spec_loss'] = generator_spec_loss.item()
        current_loss['train/gen/lfm_loss'] = generator_lfm_loss.item()
        current_loss['train/dis/label_real'] = discriminator_label_real.item()
        current_loss['train/dis/label_fake'] = discriminator_label_fake.item()
        current_loss['train/gen/lr'] = generator_lr_scheduler.get_last_lr()[0]
        current_loss['train/dis/lr'] = discriminator_lr_scheduler.get_last_lr()[0]
        self.log_dict(current_loss)

        return current_loss
    
    def log_dict(self, dic):
        # Neptune log
        if self.run != None:
            for key, value in dic.items():
                self.run[key].log(value=value, step=self.global_step)

    def validation_step(self, batch, batch_idx):
        image, target = batch
        
        # Generator Feed-Forward
        generator_prediction = self.forward(image)
        #generator_prediction = torch.clip(generator_prediction, 0, 1)
        # Generator Metrics
        generator_psnr = peak_signal_noise_ratio(generator_prediction, target)
        generator_ssim = structural_similarity_index_measure(generator_prediction, target)
        discriminator_prediction_fake = self.discriminator(image, generator_prediction)
        generator_accuracy = accuracy(discriminator_prediction_fake[0], torch.ones_like(discriminator_prediction_fake[0], dtype=torch.int32), task='binary')
        generator_rase = relative_average_spectral_error(generator_prediction.add(1).mul(0.5), target.add(1).mul(0.5))
        generator_spectral_angle = spectral_angle_mapper(generator_prediction, target)
        
        # Discriminator Feed-Forward
        discriminator_prediction_real = self.discriminator(image, target)
        discriminator_prediction_fake = self.discriminator(image, generator_prediction)
        # Discriminator Metrics
        discriminator_accuracy = accuracy(discriminator_prediction_real[0], torch.ones_like(discriminator_prediction_real[0], dtype=torch.int32), task='binary') * 0.5 + \
                                accuracy(discriminator_prediction_fake[0], torch.zeros_like(discriminator_prediction_fake[0], dtype=torch.int32), task='binary') * 0.5
            
        # Logging
        metrics = {'val/gen/psnr': generator_psnr, 'val/gen/ssim': generator_ssim, 
                   'val/gen/accuracy': generator_accuracy, 'val/dis/accuracy': discriminator_accuracy,
                   'val/gen/rase': generator_rase, 'val/gen/sam': generator_spectral_angle}
        if self.global_step != 0:
            self.log_dict(metrics)

        # Example images
        plot = u.create_plot(generator_prediction, target, epoch=self.current_epoch)
        if self.run != None:
            self.run[f"examples/example_list"].append(value=plot, step=self.global_step)
            if self.current_epoch%20 == 0:
                self.run[f"examples/example_{self.current_epoch}"].upload(plot)
        return metrics


if __name__ == "__main__":
    pass